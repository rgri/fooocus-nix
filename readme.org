*Non-cherry-picked* random batch by just typing two words "forest elf",

without any parameter tweaking, without any strange prompt tags.

See also *non-cherry-picked* generalization and diversity tests
[[https://github.com/lllyasviel/Fooocus/discussions/808][here]] and
[[https://github.com/lllyasviel/Fooocus/discussions/679][here]] and
[[https://github.com/lllyasviel/Fooocus/discussions/679#realistic][here]].

In the entire open source community, only Fooocus can achieve this level
of *non-cherry-picked* quality.

* Fooocus
:PROPERTIES:
:ID:       1c22f0b9-7216-4b15-b1cc-93c3df4b59a8
:END:
Fooocus is an image generating software (based on
[[https://www.gradio.app/][Gradio]]).

Fooocus is a rethinking of Stable Diffusion and Midjourney's designs:

- Learned from Stable Diffusion, the software is offline, open source,
  and free.

- Learned from Midjourney, the manual tweaking is not needed, and users
  only need to focus on the prompts and images.

Fooocus has included and automated [[#tech_list][lots of inner
optimizations and quality improvements]]. Users can forget all those
difficult technical parameters, and just enjoy the interaction between
human and computer to "explore new mediums of thought and expanding the
imaginative powers of the human species" =[1]=.

Fooocus has simplified the installation. Between pressing "download" and
generating the first image, the number of needed mouse clicks is
strictly limited to less than 3. Minimal GPU memory requirement is 4GB
(Nvidia).

=[1]= David Holz, 2019.

** [[*Download][Installing Fooocus]]
:PROPERTIES:
:ID:       ac352c38-5ff2-424e-946f-b0f8e3b26515
:END:
* Moving from Midjourney to Fooocus
:PROPERTIES:
:ID:       d5b25239-dfa7-4f53-916c-83101dd2e2cd
:END:
Using Fooocus is as easy as (probably easier than) Midjourney -- but
this does not mean we lack functionality. Below are the details.

| Midjourney                                                                                                | Fooocus                                                                                                                                                                                                                                                                                                                                                         |
|-----------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| High-quality text-to-image without needing much prompt engineering or parameter tuning. (Unknown method)  | High-quality text-to-image without needing much prompt engineering or parameter tuning. (Fooocus has offline GPT-2 based prompt processing engine and lots of sampling improvements so that results are always beautiful, no matter your prompt is as short as "house in garden" or as long as 1000 words)                                                      |
| V1 V2 V3 V4                                                                                               | Input Image -> Upscale or Variation -> Vary (Subtle) / Vary (Strong)                                                                                                                                                                                                                                                                                            |
| U1 U2 U3 U4                                                                                               | Input Image -> Upscale or Variation -> Upscale (1.5x) / Upscale (2x)                                                                                                                                                                                                                                                                                            |
| Inpaint / Up / Down / Left / Right (Pan)                                                                  | Input Image -> Inpaint or Outpaint -> Inpaint / Up / Down / Left / Right (Fooocus uses its own inpaint algorithm and inpaint models so that results are more satisfying than all other software that uses standard SDXL inpaint method/model)                                                                                                                   |
| Image Prompt                                                                                              | Input Image -> Image Prompt (Fooocus uses its own image prompt algorithm so that result quality and prompt understanding are more satisfying than all other software that uses standard SDXL methods like standard IP-Adapters or Revisions)                                                                                                                    |
| --style                                                                                                   | Advanced -> Style                                                                                                                                                                                                                                                                                                                                               |
| --stylize                                                                                                 | Advanced -> Advanced -> Guidance                                                                                                                                                                                                                                                                                                                                |
| --niji                                                                                                    | [[https://github.com/lllyasviel/Fooocus/discussions/679][Multiple launchers: "run.bat", "run_anime.bat", and "run_realistic.bat".]] Fooocus support SDXL models on Civitai (You can google search "Civitai" if you do not know about it)                                                                                                                        |
| --quality                                                                                                 | Advanced -> Quality                                                                                                                                                                                                                                                                                                                                             |
| --repeat                                                                                                  | Advanced -> Image Number                                                                                                                                                                                                                                                                                                                                        |
| Multi Prompts (::)                                                                                        | Just use multiple lines of prompts                                                                                                                                                                                                                                                                                                                              |
| Prompt Weights                                                                                            | You can use ” I am (happy:1.5)". Fooocus uses A1111's reweighting algorithm so that results are better than ComfyUI if users directly copy prompts from Civitai. (Because if prompts are written in ComfyUI's reweighting, users are less likely to copy prompt texts as they prefer dragging files) To use embedding, you can use"(embedding:file_name:1.1)”   |
| --no                                                                                                      | Advanced -> Negative Prompt                                                                                                                                                                                                                                                                                                                                     |
| --ar                                                                                                      | Advanced -> Aspect Ratios                                                                                                                                                                                                                                                                                                                                       |
| InsightFace                                                                                               | Input Image -> Image Prompt -> Advanced -> FaceSwap                                                                                                                                                                                                                                                                                                             |

We also have a few things borrowed from the best parts of LeonardoAI:

| LeonardoAI                                                | Fooocus                                          |
|-----------------------------------------------------------+--------------------------------------------------|
| Prompt Magic                                              | Advanced -> Style -> Fooocus V2                  |
| Advanced Sampler Parameters (like Contrast/Sharpness/etc) | Advanced -> Advanced -> Sampling Sharpness / etc |
| User-friendly ControlNets                                 | Input Image -> Image Prompt -> Advanced          |

Fooocus also developed many "fooocus-only" features for advanced users
to get perfect results.
[[https://github.com/lllyasviel/Fooocus/discussions/117][Click here to
browse the advanced features.]]

* Download
:PROPERTIES:
:ID:       98e554a1-f9ae-4637-97ac-70aec03d292e
:END:
You can directly download Fooocus with:

*[[https://github.com/lllyasviel/Fooocus/releases/download/release/Fooocus_win64_2-1-791.7z][>>>
Click here to download <<<]]*

After you download the file, please uncompress it, and then run the
"run.bat".

#+caption: image
[[https://github.com/lllyasviel/Fooocus/assets/19834515/c49269c4-c274-4893-b368-047c401cc58c]]

In the first time you launch the software, it will automatically
download models:

1. It will download [[#models][default models]] to the folder
   "Fooocus\models\checkpoints" given different presets. You can
   download them in advance if you do not want automatic download.
2. Note that if you use inpaint, at the first time you inpaint an image,
   it will download
   [[https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch][Fooocus's
   own inpaint control model from here]] as the file
   “Fooocus\models\inpaint\inpaint_v26.fooocus.patch” (the size of this
   file is 1.28GB).

After Fooocus 2.1.60, you will also have =run_anime.bat= and
=run_realistic.bat=. They are different model presets (and requires
different models, but they will be automatically downloaded).
[[https://github.com/lllyasviel/Fooocus/discussions/679][Check here for
more details]].

#+caption: image
[[https://github.com/lllyasviel/Fooocus/assets/19834515/d386f817-4bd7-490c-ad89-c1e228c23447]]

If you already have these files, you can copy them to the above
locations to speed up installation.

Note that if you see *"MetadataIncompleteBuffer" or
"PytorchStreamReader"*, then your model files are corrupted. Please
download models again.

Below is a test on a relatively low-end laptop with *16GB System RAM*
and *6GB VRAM* (Nvidia 3060 laptop). The speed on this machine is about
1.35 seconds per iteration. Pretty impressive -- nowadays laptops with
3060 are usually at very acceptable price.

#+caption: image
[[https://github.com/lllyasviel/Fooocus/assets/19834515/938737a5-b105-4f19-b051-81356cb7c495]]

Besides, recently many other software report that Nvidia driver above
532 is sometimes 10x slower than Nvidia driver 531. If your generation
time is very long, consider download
[[https://www.nvidia.com/download/driverResults.aspx/199991/en-us/][Nvidia
Driver 531 Laptop]] or
[[https://www.nvidia.com/download/driverResults.aspx/199990/en-us/][Nvidia
Driver 531 Desktop]].

Note that the minimal requirement is *4GB Nvidia GPU memory (4GB VRAM)*
and *8GB system memory (8GB RAM)*. This requires using Microsoft's
Virtual Swap technique, which is automatically enabled by your Windows
installation in most cases, so you often do not need to do anything
about it. However, if you are not sure, or if you manually turned it off
(would anyone really do that?), or *if you see any "RuntimeError:
CPUAllocator"*, you can enable it here:

#+begin_html
  <details>
#+end_html

#+begin_html
  <summary>
#+end_html

Click here to the see the image instruction.

#+begin_html
  </summary>
#+end_html

#+caption: image
[[https://github.com/lllyasviel/Fooocus/assets/19834515/2a06b130-fe9b-4504-94f1-2763be4476e9]]

*And make sure that you have at least 40GB free space on each drive if
you still see "RuntimeError: CPUAllocator" !*

#+begin_html
  </details>
#+end_html

Please open an issue if you use similar devices but still cannot achieve
acceptable performances.

*** Colab
:PROPERTIES:
:ID:       c3b9a9dd-0e67-48cf-b888-a906905ad86d
:END:
(Last tested - 2023 Nov 15)

| Colab                                                                                                                                                       | Info             |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------|
| [[https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb][[[https://colab.research.google.com/assets/colab-badge.svg]]]] | Fooocus Official |

In Colab, you can modify the last line to
=!python entry_with_update.py --share= or
=!python entry_with_update.py --preset anime --share= or
=!python entry_with_update.py --preset realistic --share= for Fooocus
Default/Anime/Realistic Edition.

Note that this Colab will disable refiner by default because Colab
free's resource is relatively limited.

Thanks to [[https://github.com/camenduru][camenduru]]!

*** Linux (Using Anaconda)
:PROPERTIES:
:ID:       eddd4ed4-b0a7-4bbf-a8a2-246a52a774e9
:END:
If you want to use Anaconda/Miniconda, you can

#+begin_example
git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
conda env create -f environment.yaml
conda activate fooocus
pip install -r requirements_versions.txt
#+end_example

Then download the models: download [[#models][default models]] to the
folder "Fooocus\models\checkpoints". *Or let Fooocus automatically
download the models* using the launcher:

#+begin_example
conda activate fooocus
python entry_with_update.py
#+end_example

Or if you want to open a remote port, use

#+begin_example
conda activate fooocus
python entry_with_update.py --listen
#+end_example

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

*** Linux (Using Python Venv)
:PROPERTIES:
:ID:       fc6971a1-4abc-4407-85f1-f009dd5a310a
:END:
Your Linux needs to have *Python 3.10* installed, and lets say your
Python can be called with command *python3* with your venv system
working, you can

#+begin_example
git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
python3 -m venv fooocus_env
source fooocus_env/bin/activate
pip install -r requirements_versions.txt
#+end_example

See the above sections for model downloads. You can launch the software
with:

#+begin_example
source fooocus_env/bin/activate
python entry_with_update.py
#+end_example

Or if you want to open a remote port, use

#+begin_example
source fooocus_env/bin/activate
python entry_with_update.py --listen
#+end_example

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

*** Linux (Using native system Python)
:PROPERTIES:
:ID:       8c6fd723-9f5c-41c5-a980-91c542525692
:END:
If you know what you are doing, and your Linux already has *Python 3.10*
installed, and your Python can be called with command *python3* (and Pip
with *pip3*), you can

#+begin_example
git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
pip3 install -r requirements_versions.txt
#+end_example

See the above sections for model downloads. You can launch the software
with:

#+begin_example
python3 entry_with_update.py
#+end_example

Or if you want to open a remote port, use

#+begin_example
python3 entry_with_update.py --listen
#+end_example

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

*** Linux (AMD GPUs)
:PROPERTIES:
:ID:       47111125-7daf-4fff-aae0-14af1ffa02c6
:END:
Same with the above instructions. You need to change torch to AMD
version

#+begin_example
pip uninstall torch torchvision torchaudio torchtext functorch xformers 
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
#+end_example

AMD is not intensively tested, however. The AMD support is in beta.

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

*** Windows(AMD GPUs)
:PROPERTIES:
:ID:       474c7177-5e77-4c84-a3e7-0185439dcb67
:END:
Same with Windows. Download the software, edit the content of =run.bat=
as:

#+begin_example
.\python_embeded\python.exe -m pip uninstall torch torchvision torchaudio torchtext functorch xformers -y
.\python_embeded\python.exe -m pip install torch-directml
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --directml
pause
#+end_example

Then run the =run.bat=.

AMD is not intensively tested, however. The AMD support is in beta.

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

*** Mac
:PROPERTIES:
:ID:       f05bb0a9-f9a2-4042-bc28-791887809c1d
:END:
Mac is not intensively tested. Below is an unofficial guideline for
using Mac. You can discuss problems
[[https://github.com/lllyasviel/Fooocus/pull/129][here]].

You can install Fooocus on Apple Mac silicon (M1 or M2) with macOS
'Catalina' or a newer version. Fooocus runs on Apple silicon computers
via [[https://pytorch.org/get-started/locally/][PyTorch]] MPS device
acceleration. Mac Silicon computers don't come with a dedicated graphics
card, resulting in significantly longer image processing times compared
to computers with dedicated graphics cards.

1. Install the conda package manager and pytorch nightly. Read the
   [[https://developer.apple.com/metal/pytorch/][Accelerated PyTorch
   training on Mac]] Apple Developer guide for instructions. Make sure
   pytorch recognizes your MPS device.
2. Open the macOS Terminal app and clone this repository with
   =git clone https://github.com/lllyasviel/Fooocus.git=.
3. Change to the new Fooocus directory, =cd Fooocus=.
4. Create a new conda environment,
   =conda env create -f environment.yaml=.
5. Activate your new conda environment, =conda activate fooocus=.
6. Install the packages required by Fooocus,
   =pip install -r requirements_versions.txt=.
7. Launch Fooocus by running =python entry_with_update.py=. (Some Mac M2
   users may need =python entry_with_update.py --enable-smart-memory= to
   speed up model loading/unloading.) The first time you run Fooocus, it
   will automatically download the Stable Diffusion SDXL models and will
   take a significant time, depending on your internet connection.

Use =python entry_with_update.py --preset anime= or
=python entry_with_update.py --preset realistic= for Fooocus
Anime/Realistic Edition.

** Default Models
:PROPERTIES:
:ID:       b4f5cd15-d4d9-4a22-a0d3-f9f432e028c7
:END:

Given different goals, the default models and configs of Fooocus is
different:

| Task      | Windows           | Linux args         | Main Model                                                                                                                                    | Refiner                                                                                                                     | Config                                                                           |
|-----------+-------------------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------|
| General   | run.bat           |                    | [[https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_version6Rundiffusion.safetensors][juggernautXL v6_RunDiffusion]] | not used                                                                                                                    | [[https://github.com/lllyasviel/Fooocus/blob/main/modules/path.py][here]]        |
| Realistic | run_realistic.bat | --preset realistic | [[https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticStockPhoto_v10.safetensors][realistic_stock_photo]]                  | not used                                                                                                                    | [[https://github.com/lllyasviel/Fooocus/blob/main/presets/realistic.json][here]] |
| Anime     | run_anime.bat     | --preset anime     | [[https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/bluePencilXL_v050.safetensors][bluepencil_v50]]                               | [[https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/DreamShaper_8_pruned.safetensors][dreamsharper_v8]] (SD1.5) | [[https://github.com/lllyasviel/Fooocus/blob/main/presets/anime.json][here]]     |

Note that the download is *automatic* - you do not need to do anything
if the internet connection is okay. However, you can download them
manually if you (or move them from somewhere else) have your own
preparation.

** List of "Hidden" Tricks
:PROPERTIES:
:ID:       97002fec-0dc8-456c-b391-17377df2a52c
:END:

Below things are already inside the software, and *users do not need to
do anything about these*.

1. GPT2-based
   [[https://github.com/lllyasviel/Fooocus/discussions/117#raw][prompt
   expansion as a dynamic style "Fooocus V2".]] (similar to Midjourney's
   hidden pre-processsing and "raw" mode, or the LeonardoAI's Prompt
   Magic).
2. Native refiner swap inside one single k-sampler. The advantage is
   that now the refiner model can reuse the base model's momentum (or
   ODE's history parameters) collected from k-sampling to achieve more
   coherent sampling. In Automatic1111's high-res fix and ComfyUI's node
   system, the base model and refiner use two independent k-samplers,
   which means the momentum is largely wasted, and the sampling
   continuity is broken. Fooocus uses its own advanced k-diffusion
   sampling that ensures seamless, native, and continuous swap in a
   refiner setup. (Update Aug 13: Actually I discussed this with
   Automatic1111 several days ago and it seems that the "native refiner
   swap inside one single k-sampler" is
   [[https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/12371][merged]]
   into the dev branch of webui. Great!)
3. Negative ADM guidance. Because the highest resolution level of XL
   Base does not have cross attentions, the positive and negative
   signals for XL's highest resolution level cannot receive enough
   contrasts during the CFG sampling, causing the results look a bit
   plastic or overly smooth in certain cases. Fortunately, since the
   XL's highest resolution level is still conditioned on image aspect
   ratios (ADM), we can modify the adm on the positive/negative side to
   compensate for the lack of CFG contrast in the highest resolution
   level. (Update Aug 16, the IOS App
   [[https://apps.apple.com/us/app/draw-things-ai-generation/id6444050820][Drawing
   Things]] will support Negative ADM Guidance. Great!)
4. We implemented a carefully tuned variation of the Section 5.1 of
   [[https://arxiv.org/pdf/2210.00939.pdf]["Improving Sample Quality of
   Diffusion Models Using Self-Attention Guidance"]]. The weight is set
   to very low, but this is Fooocus's final guarantee to make sure that
   the XL will never yield overly smooth or plastic appearance (examples
   [[https://github.com/lllyasviel/Fooocus/discussions/117#sharpness][here]]).
   This can almostly eliminate all cases that XL still occasionally
   produce overly smooth results even with negative ADM guidance.
   (Update 2023 Aug 18, the Gaussian kernel of SAG is changed to an
   anisotropic kernel for better structure preservation and fewer
   artifacts.)
5. We modified the style templates a bit and added the
   "cinematic-default".
6. We tested the "sd_xl_offset_example-lora_1.0.safetensors" and it
   seems that when the lora weight is below 0.5, the results are always
   better than XL without lora.
7. The parameters of samplers are carefully tuned.
8. Because XL uses positional encoding for generation resolution, images
   generated by several fixed resolutions look a bit better than that
   from arbitrary resolutions (because the positional encoding is not
   very good at handling int numbers that are unseen during training).
   This suggests that the resolutions in UI may be hard coded for best
   results.
9. Separated prompts for two different text encoders seem unnecessary.
   Separated prompts for base model and refiner may work but the effects
   are random, and we refrain from implement this.
10. DPM family seems well-suited for XL, since XL sometimes generates
    overly smooth texture but DPM family sometimes generate overly dense
    detail in texture. Their joint effect looks neutral and appealing to
    human perception.
11. A carefully designed system for balancing multiple styles as well as
    prompt expansion.
12. Using automatic1111's method to normalize prompt emphasizing. This
    significantly improve results when users directly copy prompts from
    civitai.
13. The joint swap system of refiner now also support img2img and
    upscale in a seamless way.
14. CFG Scale and TSNR correction (tuned for SDXL) when CFG is bigger
    than 10.

** Customization
:PROPERTIES:
:ID:       0c39195c-4fce-475a-8c73-f658d4b70102
:END:
After the first time you run Fooocus, a config file will be generated at
=Fooocus\config.txt=. This file can be edited for changing the model
path or default parameters.

For example, an edited =Fooocus\config.txt= (this file will be generated
after the first launch) may look like this:

#+begin_src json
{
    "path_checkpoints": "D:\\Fooocus\\models\\checkpoints",
    "path_loras": "D:\\Fooocus\\models\\loras",
    "path_embeddings": "D:\\Fooocus\\models\\embeddings",
    "path_vae_approx": "D:\\Fooocus\\models\\vae_approx",
    "path_upscale_models": "D:\\Fooocus\\models\\upscale_models",
    "path_inpaint": "D:\\Fooocus\\models\\inpaint",
    "path_controlnet": "D:\\Fooocus\\models\\controlnet",
    "path_clip_vision": "D:\\Fooocus\\models\\clip_vision",
    "path_fooocus_expansion": "D:\\Fooocus\\models\\prompt_expansion\\fooocus_expansion",
    "path_outputs": "D:\\Fooocus\\outputs",
    "default_model": "realisticStockPhoto_v10.safetensors",
    "default_refiner": "",
    "default_loras": [["lora_filename_1.safetensors", 0.5], ["lora_filename_2.safetensors", 0.5]],
    "default_cfg_scale": 3.0,
    "default_sampler": "dpmpp_2m",
    "default_scheduler": "karras",
    "default_negative_prompt": "low quality",
    "default_positive_prompt": "",
    "default_styles": [
        "Fooocus V2",
        "Fooocus Photograph",
        "Fooocus Negative"
    ]
}
#+end_src

Many other keys, formats, and examples are in
=Fooocus\config_modification_tutorial.txt= (this file will be generated
after the first launch).

Consider twice before you really change the config. If you find yourself
breaking things, just delete =Fooocus\config.txt=. Fooocus will go back
to default.

A safter way is just to try "run_anime.bat" or "run_realistic.bat" -
they should be already good enough for different tasks.

~Note that =user_path_config.txt= is deprecated and will be removed
soon.~ (Edit: it is already removed.)

** Advanced Features
:PROPERTIES:
:ID:       d8dfd877-20be-4aca-9f84-93ddcfeffbce
:END:
[[https://github.com/lllyasviel/Fooocus/discussions/117][Click here to
browse the advanced features.]]

Fooocus also has many community forks, just like SD-WebUI's
[[https://github.com/vladmandic/automatic][vladmandic/automatic]] and
[[https://github.com/anapnoe/stable-diffusion-webui-ux][anapnoe/stable-diffusion-webui-ux]],
for enthusiastic users who want to try!

| Fooocus' forks                                                                                                                                                                                                                            |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [[https://github.com/fenneishi/Fooocus-Control][fenneishi/Fooocus-Control]] [[https://github.com/runew0lf/RuinedFooocus][runew0lf/RuinedFooocus]] [[https://github.com/MoonRide303/Fooocus-MRE][MoonRide303/Fooocus-MRE]] and so on ...   |

See also [[https://github.com/lllyasviel/Fooocus/discussions/699][About
Forking and Promotion of Forks]].

** Thanks
:PROPERTIES:
:ID:       b6730383-4587-4fb8-880c-d389b44841bf
:END:
Fooocus is powered by
[[https://github.com/lllyasviel/Fooocus/tree/main/backend][FCBH
backend]], which starts from an odd mixture of
[[https://github.com/AUTOMATIC1111/stable-diffusion-webui][Automatic1111]]
and [[https://github.com/comfyanonymous/ComfyUI][ComfyUI]].

Special thanks to [[https://github.com/twri][twri]] and
[[https://github.com/3Diva][3Diva]] for creating additional SDXL styles
available in Fooocus.

** Update Log
:PROPERTIES:
:ID:       9604731f-10c4-4ab2-b057-622cfcae03d3
:END:
The log is [[file:update_log.md][here]].

** Localization/Translation/I18N
:PROPERTIES:
:ID:       904b25c4-1630-426f-b2d9-ad3ab8341cba
:END:
*We need your help!* Please help with translating Fooocus to
international languages.

You can put json files in the =language= folder to translate the user
interface.

For example, below is the content of =Fooocus/language/example.json=:

#+begin_src json
{
  "Generate": "生成",
  "Input Image": "入力画像",
  "Advanced": "고급",
  "SAI 3D Model": "SAI 3D Modèle"
}
#+end_src

If you add =--language example= arg, Fooocus will read
=Fooocus/language/example.json= to translate the UI.

For example, you can edit the ending line of Windows =run.bat= as

#+begin_example
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example
#+end_example

Or =run_anime.bat= as

#+begin_example
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset anime
#+end_example

Or =run_realistic.bat= as

#+begin_example
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset realistic
#+end_example

For practical translation, you may create your own file like
=Fooocus/language/jp.json= or =Fooocus/language/cn.json= and then use
flag =--language jp= or =--language cn=. Apparently, these files do not
exist now. *We need your help to create these files!*

Note that if no =--language= is given and at the same time
=Fooocus/language/default.json= exists, Fooocus will always load
=Fooocus/language/default.json= for translation. By default, the file
=Fooocus/language/default.json= does not exist.
* Fooocus and Nix
:PROPERTIES:
:ID:       4b57d0ca-305d-4051-9d53-32bde3ca3f30
:END:
AMD dev environment for the fooocus SD GUI. Stolen with respect from [[https://github.com/Nebucatnetzer/Fooocus][Nebucatnetzer]], who provides the Nvidia counterpart.
